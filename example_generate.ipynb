{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from antislop_generate import generate_antislop, chat_antislop\n",
    "\n",
    "# Enable efficient transfer for Hugging Face models\n",
    "os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = \"1\"\n",
    "\n",
    "# Set the device to 'cuda' if available, else 'cpu'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Specify the model name (replace with your preferred model)\n",
    "model_name = \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "#model.pad_token_id = tokenizer.eos_token_id\n",
    "model.to(device)\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "if os.path.exists('slop_phrase_prob_adjustments.json'):\n",
    "    with open('slop_phrase_prob_adjustments.json', 'r') as f:\n",
    "        slop_phrase_prob_adjustments = dict(json.load(f)[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a story about Elara, the weaver of tapestries in future Technopolis. In the bustling city, a group of \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "In the year 2178, in the sprawling city of Chronos, the air was alive with the hum of holographic advertisements and the soft glow of luminescent streets. In a small, cozy workshop tucked away in the winding alleys of the sprawling city, a young woman named Elianor worked her magic. Her fingers danced across the loom, weaving a tale of wonder and magic.\n",
      "\n",
      "For as long as anyone could remember, Elianor had been the go-to weaver for the city's elite, crafting tapestries that told the stories of the past, present, and future. Her workshop was a treasure trove of colors, threads, and ancient tomes, each one containing the secrets of the universe.\n",
      "\n",
      "Elianor's latest commission was a particularly intriguing one â€“ a massive, ornate loom that would be the centerpiece of the prestigious Azure Palace. The client, a powerful merchant named Cassius, was eager to showcase his latest venture: a futuristic, self-sustaining ecosystem that would feed the entire city.\n",
      "\n",
      "As Elianor worked on the loom, her mind wandered to the ancient stories her grandmother used to tell her. She remembered the tales of the great weavers of old, who had woven not just fabrics, but entire worlds into their tapestries. The whispers of the cosmos, the secrets of the earth, and the mysteries of the universe were all woven into the very fabric of her loom.\n",
      "\n",
      "The threads seemed to come alive in Elianor's hands as she worked, shimmering with an otherworldly light. She wove in patterns that danced across the fabric, weaving together threads of silver, gold"
     ]
    }
   ],
   "source": [
    "# Chat generation with streaming\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "for token in chat_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    messages=messages,\n",
    "    max_length=400,\n",
    "    # Antislop sampling may be less reliable at low temperatures.\n",
    "    temperature=1,    \n",
    "    min_p=0.1,\n",
    "    # The adjustment_strength param scales how strongly the probability adjustments are applied.\n",
    "    # A value of 1 means the values in slop_phrase_prob_adjustments (or the defaults) are used unmodified.\n",
    "    # Reasonable values are 0 (disabled) thru 10+ (effectively banning the list).\n",
    "    adjustment_strength=10.0,\n",
    "    # Optional: Provide a list of slop phrases and probability adjustments\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    streaming=True\n",
    "):\n",
    "    print(tokenizer.decode(token), end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "In the heart of the sprawling city of Cygnus, where steel and crystal towers pierced the sky and neon lights danced across the rooftops, there lived a weaver like no other. Her name was Lyra, but to the inhabitants of Cygnus, she was known as the Weaver of Dreams.\n",
      "\n",
      "Lyra's fingers moved deftly, her hands weaving a magic that had been passed down through generations of her family. She lived in a small, intricately carved wooden cottage on the outskirts of the city, surrounded by rows of shelves filled with threads of every color, hue, and texture. The air was thick with the scent of wool and magic, and the soft hum of the city's machinery provided a constant background thrum.\n",
      "\n",
      "It was here that Lyra spent her days, lost in the rhythmic dance of the loom, her threads dancing across the fabric as she wove tales of ancient myths and forgotten lore. The city's inhabitants whispered about Lyra's abilities, some hailing her as a sorceress, others a genius, and still others a simple weaver with a gift.\n",
      "\n",
      "One day, a young apprentice named Kaelin arrived at the Weaver's Cottage, seeking to learn the ancient craft from the master weaver herself. Kaelin was a curious and restless soul, with eyes that shone like the stars on a clear night and hair as dark as the night sky. He had heard tales of Lyra's legendary tapestries, said to hold the secrets of the cosmos within their swirling patterns.\n",
      "\n",
      "As Kaelin watched Lyra weave, he was entranced by the way her fingers moved in perfect synchrony with\n"
     ]
    }
   ],
   "source": [
    "# Chat generation without streaming\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "generated_text = chat_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    messages=messages,\n",
    "    max_length=400,\n",
    "    temperature=1,\n",
    "    min_p=0.1,\n",
    "    adjustment_strength=2.0,\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    streaming=False\n",
    ")\n",
    "print(tokenizer.decode(generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12-year-old twins, Astra and Lyra, stumble upon a mysterious door hidden behind a large, ancient bookshelf in the city's famous Library of Wonders.\n",
      "\n",
      "Curious about the door, the twins begin to explore it, and soon they find themselves transported to the ancient lands of Eridoria, where they meet a young woman named Eira, who possesses an extraordinary gift - the ability to weave the very fabric of reality. As they explore this mystical world, they learn that Eira has been imprisoned by a powerful sorcerer who seeks to exploit her powers for his own gain.\n",
      "\n",
      "With Eira's help, the twins set out to rescue her and defeat the sorcerer, embarking on a thrilling adventure filled with magical creatures, ancient ruins, and forgotten technologies. Along the way, they discover that the door behind the bookshelf was not a mere coincidence, but a key to unlocking a powerful secret about their own past, and that they themselves hold the key to Eira's freedom.\n",
      "\n",
      "As they delve deeper into Eira's world, the twins learn about their own unique abilities, which were passed down through their family line - the ability to weave the very fabric of reality. They must use their combined skills to outwit the sorcerer's minions, solve ancient puzzles, and overcome their own fears and doubts to rescue Eira and\n"
     ]
    }
   ],
   "source": [
    "# generate without streaming\n",
    "generated_text = generate_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_length=300,\n",
    "    temperature=1,\n",
    "    min_p=0.1,\n",
    "    adjustment_strength=2.0,\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    streaming=False\n",
    ")        \n",
    "print(tokenizer.decode(generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20th-century musicians, led by a charismatic leader named Leo, travel to the city in a magnificent, steam-powered contraption called a 'Voxtronic'.\n",
      "The group is a motley crew of artists, musicians, and inventors, each with their own unique skills and talents. There's Jax, the skilled engineer who designed the Voxtronic; Lena, the brilliant artist who created the magnificent tapestries that adorn the walls of the city's grand squares; and Zephyr, the charismatic leader who has a vision for a utopian society in the city.\n",
      "\n",
      "As they arrive in future Temporalia, the group is struck by the city's breathtaking beauty and advanced technology. The city is a marvel of interconnected systems and sustainable energy, where humans and machines coexist in harmony. The air is filled with the hum of holographic advertisements and the soft glow of luminescent orbs that illuminate the streets.\n",
      "\n",
      "The group decides to form a community in the city, where they can live and work together in peace. They settle in a beautiful, sprawling complex of interconnected buildings, with Jax's Voxtronic at its heart. The city's infrastructure is designed to support the needs of both the inhabitants and the machines, with advanced AI systems that prioritize the well-being of all beings.\n",
      "\n",
      "As the community grows, the group begins to"
     ]
    }
   ],
   "source": [
    "# generate with streaming\n",
    "for token in generate_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_length=300,\n",
    "    temperature=1,\n",
    "    min_p=0.1,\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    adjustment_strength=2.0,\n",
    "    streaming=True\n",
    "):\n",
    "    print(tokenizer.decode(token), end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
