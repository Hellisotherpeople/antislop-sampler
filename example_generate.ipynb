{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies:\n",
    "\n",
    "#!pip install transformers ipywidgets IPython\n",
    "\n",
    "# If running on Colab:\n",
    "#!git clone https://github.com/sam-paech/antislop-sampler.git\n",
    "#!mv antislop-sampler/src .\n",
    "#!mv antislop-sampler/slop_phrase_prob_adjustments.json ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from src.antislop_generate import generate_antislop, chat_antislop\n",
    "\n",
    "# Enable efficient transfer for Hugging Face models\n",
    "os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = \"1\"\n",
    "\n",
    "# Set the device to 'cuda' if available, else 'cpu'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Specify the model name (replace with your preferred model)\n",
    "model_name = \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "#model_name = \"unsloth/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, trust_remote_code=True)\n",
    "model.to(device)\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "if os.path.exists('slop_phrase_prob_adjustments.json'):\n",
    "    with open('slop_phrase_prob_adjustments.json', 'r') as f:\n",
    "        slop_phrase_prob_adjustments = dict(json.load(f)[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a story about Elara, the weaver of tapestries in future Technopolis. In the bustling city, a group of \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the heart of Future City, where sleek skyscrapers and holographic advertisements seemed to stretch on forever, a lone figure stood out among the throngs of pedestrians. Her name was Aria, but the people of this futuristic city knew her as the Weaver of Tales.\n",
      "\n",
      "Aria was a master of her craft, a weaver of extraordinary weavings that transported viewers to realms both familiar and unknown. Her studio, a small, cozy shop tucked away in a quiet alley, was a haven of warm colors and soft sounds, where the scent of wool and spices mingled with the hum of holographic machines.\n",
      "\n",
      "As the sun began to set, casting a golden glow over the city, Aria would take her latest commission from the esteemed Guild of Storykeepers, a group of revered artisans responsible for preserving the city's rich cultural heritage. These esteemed weavers were tasked with creating breathtaking weavings that told the stories of the city's history, myths, and legends.\n",
      "\n",
      "Tonight, Aria was working on a particularly special project, one that would transport viewers to the mythical lands of Eridoria, a place of ancient magic and forgotten knowledge. The Guild had commissioned her to weave a breathtakingly detailed depiction of the Eridorian Kingdom, complete with rolling hills, shimmering waterfalls, and treacherous mountain ranges.\n",
      "\n",
      "As Aria worked her magic, her fingers moved deftly, weaving threads of silver and gold into a rich brocade that seemed to shimmer and glow in the fading light. The air was filled with the sweet scent of blooming flowers, and the soft hum of the machines in the studio created a soothing melody that seemed to lull the city's inhabitants into a peaceful reverie.\n",
      "\n",
      "Just as Aria was finishing the final threads of her design, a group of curious onlookers gathered outside her shop, their eyes fixed on the majestic weavings on display. Among them was a young girl, with skin as pale as moonlight and hair as dark as the night"
     ]
    }
   ],
   "source": [
    "# Chat generation with streaming\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "tokens = []\n",
    "text = ''\n",
    "for token in chat_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    messages=messages,\n",
    "    max_new_tokens=400,\n",
    "    # Antislop sampling may be less reliable at low temperatures.\n",
    "    temperature=1,    \n",
    "    min_p=0.1,\n",
    "    # The adjustment_strength param scales how strongly the probability adjustments are applied.\n",
    "    # A value of 1 means the values in slop_phrase_prob_adjustments (or the defaults) are used unmodified.\n",
    "    # Reasonable values are 0 (disabled) thru 100+ (effectively banning the list).\n",
    "    adjustment_strength=100.0,\n",
    "    # Optional: Provide a list of slop phrases and probability adjustments\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    enforce_json=False,\n",
    "    antislop_enabled=True,\n",
    "    streaming=True,\n",
    "    stream_smoothing=True, # On by default; this will smooth out the stutters from backtracking.\n",
    "):\n",
    "    tokens.append(token)\n",
    "    full_text = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "    new_text = full_text[len(text):]\n",
    "    text = full_text\n",
    "    print(new_text, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the year 2254, in the sprawling city of New Eden, the sound of hammers ringing against steel and the hum of machinery filled the air. The city was a marvel of modern technology, where humans and AI had merged to create a utopia of efficiency and progress. But despite the wonders of this future world, there was one craftsman who stood out from the rest: a talented weaver named Eliara.\n",
      "\n",
      "Eliara lived in a small, intricately carved wooden apartment in the heart of New Eden's prestigious Upper District. Her home was a sanctuary, filled with the soft glow of luminescent fibers that infused her creations with a soft, ethereal light. The walls were adorned with Eliara's stunning works of art â€“ magnificent wall hangings that told stories of the past, present, and future.\n",
      "\n",
      "As the sun set over New Eden, casting a warm orange glow over the city, Eliara set to work on her latest commission. She had been hired to create a grand mural for the grand ballroom of the city's grandest social club, the Aurora Club. The club's patrons were known for their love of fine art, fashion, and, of course, technology.\n",
      "\n",
      "Eliara's fingers moved deftly, weaving a complex pattern of threads that seemed to shimmer and dance in the fading light. She was a master of her craft, with a deep knowledge of the ancient techniques of textile production that had been passed down through generations of weavers.\n",
      "\n",
      "As the night wore on, the ballroom came alive with the sound of laughter, music, and the soft rustle of fabrics. The patrons mingled and danced, their eyes fixed\n"
     ]
    }
   ],
   "source": [
    "# Chat generation without streaming\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "generated_text = chat_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    messages=messages,\n",
    "    max_length=400,\n",
    "    temperature=1,\n",
    "    min_p=0.1,\n",
    "    adjustment_strength=100.0,\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    enforce_json=False,\n",
    "    antislop_enabled=True,\n",
    "    streaming=False\n",
    ")\n",
    "print(tokenizer.decode(generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15-year-olds are gathered around her workshop, mesmerized by the colors and patterns that dance across her loom.\n",
      "\n",
      "The young apprentices, each with their own unique skillset and expertise, watch as their teacher expertly weaves together tales of old. The air is thick with the scent of wool and the soft hum of the loom, creating an enchanting atmosphere that is at once calming and exhilarating.\n",
      "\n",
      "As the day wears on, the group's fascination grows, and they begin to ask questions about the secrets behind her enchanted loom. One young apprentice, a skilled weaver herself, asks the question that will change the course of their lives: \"How do you weave the threads of time?\" The question sparks a flurry of excited chatter and the young teacher smiles, knowing that the moment has arrived to reveal the true magic of her craft.\n",
      "\n",
      "With a nod, she begins to weave a new tale, one that weaves together the threads of the past, present, and future, creating a breathtaking narrative that will capture the hearts and minds of all who witness it. The young apprentices watch, entranced, as the loom comes alive, spinning a story that is both timeless and timely, a reflection of the changing world around them.\n",
      "\n",
      "As the tale reaches its climax, a young girl with a mop of curly hair and a wild look in\n"
     ]
    }
   ],
   "source": [
    "# generate without streaming\n",
    "prompt_with_template = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "generated_text = generate_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_length=300,\n",
    "    temperature=1,\n",
    "    min_p=0.1,\n",
    "    adjustment_strength=100.0,\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    enforce_json=False,\n",
    "    antislop_enabled=True,\n",
    "    streaming=False\n",
    ")        \n",
    "print(tokenizer.decode(generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5 adventurers were hired for a mission to retrieve a rare and valuable artifact from the long-abandoned Spire of Eldrid.\n",
      "The group consisted of:\n",
      "- Arin the Brave, a skilled warrior with unparalleled combat prowess\n",
      "- Lyra the Enigmatic, an expert in ancient lore and forgotten technologies\n",
      "- Kael the Charismatic, a smooth-talking diplomat and negotiator\n",
      "- Mira the Scholar, a brilliant and book-smart expert in the arcane\n",
      "- and Zephyr the Wild, a fearless and agile hunter with unparalleled tracking skills.\n",
      "\n",
      "Together, the group ventured into the treacherous Spire of Eldrid, a massive structure built by the ancient Eldridians to reach the uppermost level of their sprawling city. The Spire was said to contain a treasure trove of knowledge and artifacts, but it was also rumored to be cursed, filled with deadly traps and fearsome creatures.\n",
      "\n",
      "As they reached the heart of the Spire, the group encountered a massive stone door adorned with ancient runes. Kael, with his quick wit and knowledge of ancient languages, was able to decipher the runes, revealing a hidden passage that would lead them deeper into the Spire. Arin, with his battle-hardened instincts, led the way, while Mira examined the runes and Lyra studied the ancient lore. Zephyr provided"
     ]
    }
   ],
   "source": [
    "# generate with streaming\n",
    "prompt_with_template = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "tokens = []\n",
    "text = \"\"\n",
    "for token in generate_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_length=300,\n",
    "    temperature=1,\n",
    "    min_p=0.1,\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    adjustment_strength=100.0,\n",
    "    enforce_json=False,\n",
    "    antislop_enabled=True,\n",
    "    streaming=True\n",
    "):\n",
    "    tokens.append(token)\n",
    "    full_text = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "    new_text = full_text[len(text):]\n",
    "    text = full_text\n",
    "    print(new_text, end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
