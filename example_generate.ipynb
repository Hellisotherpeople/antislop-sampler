{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies:\n",
    "\n",
    "#!pip install transformers ipywidgets IPython\n",
    "\n",
    "# If running on Colab:\n",
    "#!git clone https://github.com/sam-paech/antislop-sampler.git\n",
    "#!mv antislop-sampler/src .\n",
    "#!mv antislop-sampler/slop_phrase_prob_adjustments.json ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from src.antislop_generate import generate_antislop, chat_antislop\n",
    "\n",
    "# Enable efficient transfer for Hugging Face models\n",
    "os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = \"1\"\n",
    "\n",
    "# Set the device to 'cuda' if available, else 'cpu'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Specify the model name (replace with your preferred model)\n",
    "model_name = \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "#model_name = \"unsloth/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "#model.pad_token_id = tokenizer.eos_token_id\n",
    "model.to(device)\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "if os.path.exists('slop_phrase_prob_adjustments.json'):\n",
    "    with open('slop_phrase_prob_adjustments.json', 'r') as f:\n",
    "        slop_phrase_prob_adjustments = dict(json.load(f)[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a story about Elara, the weaver of tapestries in future Technopolis. In the bustling city, a group of \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the heart of Future Polis, where skyscrapers pierced the sky and neon lights danced across the streets, a small, unassuming shop stood out among the crowds. \"Moonwhisper's Textiles\" was the name, and \"weaver of tapestries\" was the nickname that had been whispered about for generations.\n",
      "\n",
      "Inside the shop, the air was alive with the hum of looms and the soft whisper of threads as they wove themselves into the fabric of reality. Among the rows of intricately patterned tapestries, one woman stood out - a young weaver named Eliana, known to her friends and customers as simply \"The Weaver\".\n",
      "\n",
      "Eliana's fingers moved with a precision that belied her age, her hands weaving and knotting threads into a living, breathing narrative that told stories of love, loss, and redemption. Her tapestries were more than just beautiful works of art - they were portals to other worlds, gateways to memories yet to be forged.\n",
      "\n",
      "One day, as the sun set over the city, a group of strangers entered the shop, their faces shrouded in shadows. They were a diverse bunch - a young professional, a street artist, a scientist, and a philosopher - all drawn together by the whispered rumors of The Weaver's extraordinary abilities.\n",
      "\n",
      "Their eyes widened as they took in the sheer scale of Eliana's tapestries, each one a window into a different corner of the world. The scientist's eyes lit up with excitement as she reached out to touch a particularly delicate thread, while the philosopher's eyes grew misty as she gazed upon a passage from an ancient text that seemed to shimmer with an otherworldly light.\n",
      "\n",
      "The young professional, meanwhile, approached Eliana with a curious expression on her face. \"I've heard stories about your tapestries,\" she said, her voice low and measured. \"But I've never seen one in person. Can you show me what you do?\"\n",
      "\n",
      "E"
     ]
    }
   ],
   "source": [
    "# Chat generation with streaming\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "for token in chat_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    messages=messages,\n",
    "    max_new_tokens=400,\n",
    "    # Antislop sampling may be less reliable at low temperatures.\n",
    "    temperature=1,    \n",
    "    min_p=0.1,\n",
    "    # The adjustment_strength param scales how strongly the probability adjustments are applied.\n",
    "    # A value of 1 means the values in slop_phrase_prob_adjustments (or the defaults) are used unmodified.\n",
    "    # Reasonable values are 0 (disabled) thru 100+ (effectively banning the list).\n",
    "    adjustment_strength=100.0,\n",
    "    # Optional: Provide a list of slop phrases and probability adjustments\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    enforce_json=False,\n",
    "    antislop_enabled=True,\n",
    "    streaming=True\n",
    "):\n",
    "    print(tokenizer.decode(token), end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the heart of future Terraverde, a city of unparalleled innovation and technological advancement, a small, unassuming shop stood on a narrow street lined with sleek skyscrapers. The sign above the door read \"Weaver of Dreams,\" and the windows were crowded with an assortment of peculiar items: intricately carved stone pedestals, glowing orbs that pulsed with an ethereal light, and delicate filigree threads that seemed to shimmer with an otherworldly energy.\n",
      "\n",
      "This was the domain of a young woman named Lyra, a skilled weaver of tapestries with a reputation for creating the most breathtaking works of art in all of Terraverde. Her fingers danced across the loom, weaving a mesmerizing pattern of light and shadow that seemed to capture the very essence of the city itself.\n",
      "\n",
      "Lyra's shop was a sanctuary for the people of Terraverde, a place where they could come to escape the hum of technology and the constant din of commerce. Inside, the air was thick with the scent of wool and lavender, and the soft glow of luminescent mushrooms illuminated the rows of shelves, where Lyra's wares were on display. There were tapestries of breathtaking beauty, woven from threads of gold and silver that seemed to reflect the very light of the city; others, more subtle, that whispered secrets of the wind and the stars.\n",
      "\n",
      "One day, a group of five individuals, each from a different corner of the city, walked into Lyra's shop, each carrying a message from their leader. There was Arin, a brilliant scientist from the New Eden Institute, who sought Lyra's expertise in creating a new type of textile\n"
     ]
    }
   ],
   "source": [
    "# Chat generation without streaming\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "generated_text = chat_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    messages=messages,\n",
    "    max_length=400,\n",
    "    temperature=1,\n",
    "    min_p=0.1,\n",
    "    adjustment_strength=100.0,\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    enforce_json=False,\n",
    "    antislop_enabled=True,\n",
    "    streaming=False\n",
    ")\n",
    "print(tokenizer.decode(generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " urchins have begun to notice that the weavers have been quietly adding strange symbols to their own textiles.\n",
      "\n",
      "At first, the urchins think it's just a prank or a weird art trend, but as the symbols become more prominent and seem to be telling a different story, they start to wonder if there's something more sinister at work.\n",
      "\n",
      "The urchin leader, a scrappy kid named Kael, decides to investigate further and discovers that the weavers have been adding symbols that seem to be connected to a long-forgotten event from the city's history. As Kael delves deeper into the mystery, he uncovers a dark secret that the weavers are hiding.\n",
      "\n",
      "The symbols on the tapestries are actually a warning, left by a group of rebels who fought against the corrupt ruling elite in the past. They have been trying to communicate with the city's inhabitants for generations, but their voices have been silenced by the ruling elite.\n",
      "\n",
      "Kael realizes that the weavers are not just adding symbols, they are actually trying to tell the urchins and the city's inhabitants a message of hope and resistance. They are using their textiles to spread the truth and ignite a movement for change.\n",
      "\n",
      "With this revelation, Kael rallies the urchins and together, they form a secret resistance group, using the symbols on the tape\n"
     ]
    }
   ],
   "source": [
    "# generate without streaming\n",
    "prompt_with_template = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "generated_text = generate_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_length=300,\n",
    "    temperature=1,\n",
    "    min_p=0.1,\n",
    "    adjustment_strength=100.0,\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    enforce_json=False,\n",
    "    antislop_enabled=True,\n",
    "    streaming=False\n",
    ")        \n",
    "print(tokenizer.decode(generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " urchins sneak out to watch the celestial ballet of stars in the night sky, a tradition that has been a part of the city's culture for centuries. They find a lone weaver, who is working on a new piece of fabric, and strike up a conversation. The weaver, a mysterious woman with an air of quiet determination, listens to their tale of adventure and bravery. She shares a secret of her own, one that only a select few are privy to.\n",
      "\n",
      "In the city, the weaver's skills as a weaver and a seamstress are highly sought after, as the wealthy elite use her wares to adorn their palaces and cloaks. But in the undercity, where the streets are narrow and the alleys are dark, the true value of the weaver's art lies in the hidden patterns and secret symbols that are woven into every thread. It is here that the urchins and the weaver's secret meet, and a bond is forged between them. The weaver reveals to the urchins a way to see the stars in a new and wondrous way, using the patterns and symbols that are woven into the fabric. Together, they watch the celestial ballet, and in doing so, they discover a hidden truth about their own city and its inhabitants.\n",
      "\n",
      "The story is a tale of adventure,"
     ]
    }
   ],
   "source": [
    "# generate with streaming\n",
    "prompt_with_template = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "for token in generate_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_length=300,\n",
    "    temperature=1,\n",
    "    min_p=0.1,\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    adjustment_strength=100.0,\n",
    "    enforce_json=False,\n",
    "    antislop_enabled=True,\n",
    "    streaming=True\n",
    "):\n",
    "    print(tokenizer.decode(token), end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
