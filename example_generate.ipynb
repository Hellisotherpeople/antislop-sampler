{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies:\n",
    "\n",
    "#!pip install transformers ipywidgets IPython\n",
    "\n",
    "# If running on Colab:\n",
    "#!git clone https://github.com/sam-paech/antislop-sampler.git\n",
    "#!mv antislop-sampler/src .\n",
    "#!mv antislop-sampler/slop_phrase_prob_adjustments.json ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from src.antislop_generate import generate_antislop, chat_antislop\n",
    "\n",
    "# Enable efficient transfer for Hugging Face models\n",
    "os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = \"1\"\n",
    "\n",
    "# Set the device to 'cuda' if available, else 'cpu'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Specify the model name (replace with your preferred model)\n",
    "model_name = \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "#model_name = \"unsloth/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, trust_remote_code=True)\n",
    "model.to(device)\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "if os.path.exists('slop_phrase_prob_adjustments.json'):\n",
    "    with open('slop_phrase_prob_adjustments.json', 'r') as f:\n",
    "        slop_phrase_prob_adjustments = dict(json.load(f)[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a story about Elara, the weaver of tapestries in future Technopolis. In the bustling city, a group of \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the heart of Future City, where skyscrapers pierced the clouds and holographic advertisements danced in the air, a small, mysterious shop stood out among the crowds. The sign above the door read \"Moonwhisper's Weaving\", and the windows were filled with an array of colorful threads, shimmering fabrics, and mysterious, glowing yarns.\n",
      "\n",
      "Behind the door, Moonwhisper herself worked her magic, weaving a new tale into the fabric of reality. Her long, silver hair cascaded down her back like a river of moonlight, and her eyes shone like stars in the night sky. She was a weaver of extraordinary talent, and her creations were sought after by the most discerning citizens of Future City.\n",
      "\n",
      "One day, a group of travelers arrived in the city, seeking refuge from the dangers that lurked beyond the borders. They were a ragtag bunch, with skin like parchment and hair like leaves â€“ a tribe of nomads who had been traveling the galaxy for generations. Among them was a young woman named Lyra, with skin as pale as alabaster and hair as red as the sun. She was a skilled hunter, with a bow and quiver full of arrows at her side.\n",
      "\n",
      "As Lyra entered the shop, Moonwhisper looked up from her weaving and smiled. \"Ah, a traveler,\" she said, her voice like music. \"I sense that you have stories to tell, and worlds to explore.\"\n",
      "\n",
      "The group of nomads gathered around the shop, eager to hear Moonwhisper's tales of the weaving arts. She told them of the ancient secrets she had learned from the earliest weavers, of the magical threads that danced with the wind and the stars. She spoke of the great looms that stood in the heart of the city, where the threads of reality were woven and unwoven.\n",
      "\n",
      "As the night wore on, Lyra found herself drawn to Moonwhisper's shop. She asked if she could see more of her work"
     ]
    }
   ],
   "source": [
    "# Chat generation with streaming\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "tokens = []\n",
    "text = ''\n",
    "for token in chat_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    messages=messages,\n",
    "    max_new_tokens=400,\n",
    "    # Antislop sampling may be less reliable at low temperatures.\n",
    "    temperature=1,    \n",
    "    min_p=0.1,\n",
    "    # The adjustment_strength param scales how strongly the probability adjustments are applied.\n",
    "    # A value of 1 means the values in slop_phrase_prob_adjustments (or the defaults) are used unmodified.\n",
    "    # Reasonable values are 0 (disabled) thru 100+ (effectively banning the list).\n",
    "    adjustment_strength=100.0,\n",
    "    # Optional: Provide a list of slop phrases and probability adjustments\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    enforce_json=False,\n",
    "    antislop_enabled=True,\n",
    "    streaming=True,\n",
    "    stream_smoothing=True, # On by default; this will smooth out the stutters from backtracking.\n",
    "):\n",
    "    tokens.append(token)\n",
    "    full_text = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "    new_text = full_text[len(text):]\n",
    "    text = full_text\n",
    "    print(new_text, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the heart of Future Polis, a city of breathtaking technological marvels and human ingenuity, a small, mysterious shop stood out among the steel skyscrapers and neon-lit streets. The sign above the door read \"Elyria's Weavings,\" and the windows were filled with an assortment of colorful fabrics, shimmering threads, and half-finished masterpieces.\n",
      "\n",
      "Behind the counter, a lone weaver sat, her long, silver hair woven with threads of silver and gold, her eyes shining like the stars in a midnight sky. She was a master of her craft, a weaver of tales and legends that had been passed down through generations of her family.\n",
      "\n",
      "Her name was Aethera, and she was known throughout the city as the weaver of Elyria's Weavings. Her shop was a sanctuary, a place where people could come to escape the chaos of the city and find comfort in the gentle rhythms of the loom.\n",
      "\n",
      "One day, a group of travelers arrived in the city, seeking refuge from the war-torn lands beyond the Great Wall. They were a diverse bunch, from merchants to warriors, each with their own story to tell and their own quest to find. Among them was a young man named Kael, a skilled fighter with a scar above his left eyebrow and a fire in his eyes that seemed to burn brighter with every step.\n",
      "\n",
      "Kael had been hired to escort a valuable cargo of rare textiles through the city's markets, but as he walked through the crowded streets, he felt a sense of restlessness. He longed to see the world beyond the city's walls, to feel the wind in his hair and the sun\n"
     ]
    }
   ],
   "source": [
    "# Chat generation without streaming\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "generated_text = chat_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    messages=messages,\n",
    "    max_length=400,\n",
    "    temperature=1,\n",
    "    min_p=0.1,\n",
    "    adjustment_strength=100.0,\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    enforce_json=False,\n",
    "    antislop_enabled=True,\n",
    "    streaming=False\n",
    ")\n",
    "print(tokenizer.decode(generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4 adventurers gathered at the local tavern, seeking a job. The bartender, a gruff but kind-hearted man named Grim, looked up from polishing a mug and raised an eyebrow at the group's eclectic mix.\n",
      "\n",
      "\"Looks like you lot are in search of work, eh?\" Grim asked, wiping down the bar with a dirty rag. \"What kind of job are you looking for?\"\n",
      "\n",
      "The group, consisting of a half-elf rogue, a dwarf cleric, a halfling bard, and a human wizard, exchanged glances and began to explain their skills and qualifications.\n",
      "\n",
      "\"I'm looking for something with a bit of... flair,\" said the half-elf rogue, adjusting his leather armor. \"Something that'll allow me to showcase my skills in a unique way.\"\n",
      "\n",
      "\"Ah, you're looking for something that'll make a statement,\" Grim said with a chuckle. \"Well, I might have just the thing for you lot.\"\n",
      "\n",
      "He led them to a small room in the back of the tavern, where a large, ornate loom sat on a pedestal. The loom was adorned with strange symbols and markings, and a small, glowing crystal hung from a length of thin wire.\n",
      "\n",
      "\"This is my latest creation,\" Grim said proudly. \"I call it the 'Tapesty of the Ancients.' It's said to hold the\n"
     ]
    }
   ],
   "source": [
    "# generate without streaming\n",
    "prompt_with_template = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "generated_text = generate_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_length=300,\n",
    "    temperature=1,\n",
    "    min_p=0.1,\n",
    "    adjustment_strength=100.0,\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    enforce_json=False,\n",
    "    antislop_enabled=True,\n",
    "    streaming=False\n",
    ")        \n",
    "print(tokenizer.decode(generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20,000 inhabitants live in harmony with the city's unique architecture, technology, and the magical energies of the city's core.\n",
      "\n",
      "As the sun rises over the city, the streets come alive with the sounds of hammers striking against the anvil, the clang of steel on steel, and the chatter of the 20,000 inhabitants rushing to start their day. In the heart of the city, the magnificent Temple of the Ancients stands tall, its grandeur and beauty a beacon for all to see.\n",
      "\n",
      "Among the citizens of the city, there lives a young woman named Eldra. Eldra is a skilled weaver of the most exquisite and rare materials, capable of conjuring the very essence of the city's magical energies. Her fingers dance across the loom, creating textiles so breathtaking that they have become a symbol of the city's prosperity.\n",
      "\n",
      "As Eldra works, her mind wanders to her sister, Aria, who has fallen ill with a mysterious ailment. The city's healers have tried every remedy, but Aria's condition worsens by the day. Eldra's concern for her sister grows, and she sets out to explore the city, hoping to find a solution.\n",
      "\n",
      "The streets of the city are a marvel of innovation, with levitating walkways and advanced transportation systems connecting the different districts. The air is"
     ]
    }
   ],
   "source": [
    "# generate with streaming\n",
    "prompt_with_template = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "tokens = []\n",
    "text = \"\"\n",
    "for token in generate_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_length=300,\n",
    "    temperature=1,\n",
    "    min_p=0.1,\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    adjustment_strength=100.0,\n",
    "    enforce_json=False,\n",
    "    antislop_enabled=True,\n",
    "    streaming=True\n",
    "):\n",
    "    tokens.append(token)\n",
    "    full_text = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "    new_text = full_text[len(text):]\n",
    "    text = full_text\n",
    "    print(new_text, end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
