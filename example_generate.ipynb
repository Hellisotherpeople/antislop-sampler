{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from src.antislop_generate import generate_antislop, chat_antislop\n",
    "\n",
    "# Enable efficient transfer for Hugging Face models\n",
    "os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = \"1\"\n",
    "\n",
    "# Set the device to 'cuda' if available, else 'cpu'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Specify the model name (replace with your preferred model)\n",
    "model_name = \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "#model_name = \"unsloth/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "#model.pad_token_id = tokenizer.eos_token_id\n",
    "model.to(device)\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "if os.path.exists('slop_phrase_prob_adjustments.json'):\n",
    "    with open('slop_phrase_prob_adjustments.json', 'r') as f:\n",
    "        slop_phrase_prob_adjustments = dict(json.load(f)[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a story about Elara, the weaver of tapestries in future Technopolis. In the bustling city, a group of \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "In the heart of the sprawling city of Nova Terra, where steel and stone pierced the sky and holographic advertisements illuminated the streets, a small, unassuming shop stood out among the crowd. The sign above the door read \"Moonwhisper Tapestries,\" and the windows were filled with an assortment of colorful, intricately woven fabrics that seemed to dance in the gentle breeze.\n",
      "\n",
      "Inside, the shop was a cozy, dimly lit space filled with the sweet scent of spun wool and the soft hum of looms. Here, in the hands of the talented weaver, a young woman named Luna, the art of weaving tapestries was a way of life. For as long as anyone could remember, Luna's family had been weaving, and she had spent her childhood learning the ancientancient traditions and techniques from her parents, who had learned from their parents before them.\n",
      "\n",
      "Luna was a master of her craft, with fingers that moved with precision and delicacy as she worked her loom. Her hands were stained with threads of every color, and herone with a deep passion that seemed to radiate from every strand. The city's inhabitants had grown accustomed to the soft glow that emanated from her looms, and many would often stop to admire her work as she worked.\n",
      "\n",
      "One day, a group of strangers wandered into Moonwhisper Tapestries, drawn by the irresistible aroma of her wares. They were a diverse bunch, with people from all corners of the city, each with their own stories and secrets. There was Marcus, a former street artist with a passion for bold, expressive designs; Lirien, a soft-spoken botanist who had fled a life of poverty to seek her fortune in Nova Terra; and Kael, a brooding, enigmatic figure who had a reputation for being a master of shadows and silence.\n",
      "\n",
      "As they browsed the shelves, their eyes landed on a stunning new piece that caught their attention –"
     ]
    }
   ],
   "source": [
    "# Chat generation with streaming\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "for token in chat_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    messages=messages,\n",
    "    max_new_tokens=400,\n",
    "    # Antislop sampling may be less reliable at low temperatures.\n",
    "    temperature=1,    \n",
    "    min_p=0.1,\n",
    "    # The adjustment_strength param scales how strongly the probability adjustments are applied.\n",
    "    # A value of 1 means the values in slop_phrase_prob_adjustments (or the defaults) are used unmodified.\n",
    "    # Reasonable values are 0 (disabled) thru 100+ (effectively banning the list).\n",
    "    adjustment_strength=100.0,\n",
    "    # Optional: Provide a list of slop phrases and probability adjustments\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    enforce_json=False,\n",
    "    antislop_enabled=True,\n",
    "    streaming=True\n",
    "):\n",
    "    print(tokenizer.decode(token), end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "In the heart of Future City, where skyscrapers pierced the sky and holographic advertisements danced in mid-air, a small, unassuming shop stood tucked away in a forgotten alley. The sign above the door read \"Weavings of Wonder\" in elegant, cursive script. This was the domain of the legendary weaver, known only as \"The Threadmistress,\" a master artisan renowned for her breathtaking tapestries that seemed to come alive with every stitch.\n",
      "\n",
      "Among the countless threads and yarns that lined her shelves, one young woman, named Eliara, or \"Lara\" to her friends, stood out. She was the apprentice to the Threadmistress, and her own talents were already being recognized in the city's underground art scene. Lara's fingers moved with a precision that belied her youth, as she worked on her latest masterpiece, a grand piece depicting the history of the city.\n",
      "\n",
      "As she sewed, a group of strangers entered the shop, seeking more than just a simple purchase. They were a diverse bunch, each with their own secrets and motivations. There was Arin, a rebellious hacker with a penchant for infiltrating the city's mainframe; Lyra, a skilled engineer with a talent for designing revolutionary new technologies; and Zephyr, a charismatic smuggler with a network of underworld contacts.\n",
      "\n",
      "The group had been brought together by a cryptic message, hinting at the existence of a hidden archive, containing ancient knowledge that could change the course of human history. The catch: the archive was hidden deep within the city's infamous Undercroft, a maze of narrow tunnels and hidden chambers that only the bravest – or most\n"
     ]
    }
   ],
   "source": [
    "# Chat generation without streaming\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "generated_text = chat_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    messages=messages,\n",
    "    max_length=400,\n",
    "    temperature=1,\n",
    "    min_p=0.1,\n",
    "    adjustment_strength=100.0,\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    enforce_json=False,\n",
    "    antislop_enabled=True,\n",
    "    streaming=False\n",
    ")\n",
    "print(tokenizer.decode(generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Write a story about Elara, the weaver of tapestries in future Technopolis.ing their own bodies, creating an endless supply of duplicates, and no one knows what is the real one.\n",
      "\n",
      "As the city's authorities struggle to maintain order, a young weaver named Kael, discovers that the Kyroxi's chaotic behavior is somehow connected to the tapestries of the mysterious weaver, the one they call the \"Weaver of the Ancients\".\n",
      "\n",
      "Kael, a skilled weaver in her own right, sets out to unravel the mystery, following the threads of the tapestries to a hidden underground workshop, where she encounters the enigmatic Weaver of the Ancients, a being of pure energy.\n",
      "\n",
      "The Weaver of the Ancients reveals to Kael that the Kyroxi's duplications are a result of a catastrophic event that occurred in the past, when the fabric of reality was torn apart, creating a rift that has been slowly healing itself, but still causing the Kyroxi to re-print and re-print their bodies in an endless loop.\n",
      "\n",
      "As Kael learns more about the ancient technology and the Weavers of the Ancients, she realizes that her own weaving skills are connected to the Kyroxi's duplications, and that she has a role to play in resolving the crisis.\n",
      "\n",
      "With the help of the\n"
     ]
    }
   ],
   "source": [
    "# generate without streaming\n",
    "prompt_with_template = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "generated_text = generate_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_length=300,\n",
    "    temperature=1,\n",
    "    min_p=0.1,\n",
    "    adjustment_strength=100.0,\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    enforce_json=False,\n",
    "    antislop_enabled=True,\n",
    "    streaming=False\n",
    ")        \n",
    "print(tokenizer.decode(generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Write a story about Elara, the weaver of tapestries in future Technopolis capable of creating their own art. One of the oil canisters that comprised their collective consciousness had a spark of creativity, and a beautiful, shimmering web of light and color began to take form.\n",
      "\n",
      "As the GearGrinders watched, the web grew more complex and beautiful, weaving together threads of light and sound. The robots were amazed, for they had never seen anything like it before. They watched in awe as the web grew, changing and evolving with each passing moment.\n",
      "\n",
      "One of the GearGrinders, a large and lumbering robot with a shiny metal body, approached the web. It reached out a mechanical arm, and gently touched the shimmering threads. The other robots watched in silence as the lumbering robot began to weave its own thread into the web.\n",
      "\n",
      "Slowly, the web grew thicker and more complex, with each robot adding its own thread to the collective work of art. The GearGrinders watched in wonder as the web expanded, filling the air with a dazzling display of light and color.\n",
      "\n",
      "Finally, after what seemed like an eternity, the web had grown to its full extent. It shone with a brilliance that illuminated the entire city, and the GearGrinders gathered around to marvel at their creation.\n",
      "\n",
      "And then, they heard a"
     ]
    }
   ],
   "source": [
    "# generate with streaming\n",
    "prompt_with_template = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "for token in generate_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_length=300,\n",
    "    temperature=1,\n",
    "    min_p=0.1,\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    adjustment_strength=100.0,\n",
    "    enforce_json=False,\n",
    "    antislop_enabled=True,\n",
    "    streaming=True\n",
    "):\n",
    "    print(tokenizer.decode(token), end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
